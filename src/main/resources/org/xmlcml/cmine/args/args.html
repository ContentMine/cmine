<html>
<div>
<h1>
<tt>cmine (0.1.1)</tt>
</h1>
<h2>argument <tt>input</tt>
</h2>
<code>--input [file(s)_and/or_url(s)]{1,*}</code>
<br>
<em>b: -i h:   c: </em>
<h2>Description</h2>
<help>
		  
<p>
			Input stream (Files, directories, URLs), Norma tries to guess reasonable actions. 
				also expands some simple wildcards. The argument can either be a single object, or a list. Within objects
				the content of curly brackets {...} is expanded as wildcards (cannot recurse). There can be multiple {...}
				within an object and all are expanded (but be sensible - this could generate the known universe and crash the
				system. (If this is misused it will be withdrawn). Objects (URLs, files) can be mixed but it's probably a
				poor idea.
			</p>	
			
<p>The logic is: 
				<ul>
				
<li>(a) if an object starts with 'www' or 'http:' or 'https;' it's assumed to be a URL</li>
				
<li>(b) if it is a directory, then the contents (filtered by extension) are added to the list as files</li>
				
<li>(c) if it's a file it's added to the list</li>
				
</ul>
				the wildcards in files and URLs are then expanded and the results added to the list
				</p>

				
<p>			
				Current wildcards:
				  <pre>
	  {n1:n2} n1,n2 integers: generate n1 ... n2 inclusive
	  {foo,bar,plugh} list of strings
				  </pre>
				
</p>	  
		
</help>
<h2>argument <tt>cmdir</tt>
</h2>
<code>--cmdir director(ies){0,*}</code>
<br>
<em>b: -q h:   c: </em>
<h2>Description</h2>
<help>
		NOTE WAS quickscrapeNorma
			FILE_CONTAINER:
			create directory  contentmine/some/where/journal.pone.0115884/. It may contain
			
			results.json * // a listing of scraped files
			
			fulltext.xml ? // publishers XML
			fulltext.pdf ? // publishers PDF
			fulltext.html ? // raw HTML
			provisional.pdf ? // provisional PDF (often disappears)
			
			foo12345.docx ? // data files numbered by publisher/author
			bar54321.docx ?
			ah1234.cif ? // crystallographic data
			pqr987.cml ? // chemistry file
			mmm.csv ? // table
			pic5656.png ? // images
			pic5657.gif ? // image
			suppdata.pdf ? // supplemental data
			
			and more
			
			only results.json is mandatory. However there will normally be at least one fulltext.* file and probably at 
			least one *.html file (as the landing page must be in HTML). Since quickscrape can extract data without 
			fulltext it might also be deployed against a site with data files.
			
			There may be some redundancy - *.xml may be transformable into *.html and *.pdf into *.html. The PDF may also 
			contain the same images as some exposed *.png.
		</help>
<h2>argument <tt>qsNorma</tt>
</h2>
<code>--quickscrapeNorma director(ies){1,*}</code>
<br>
<em>b: -q h:   c: </em>
<h2>Description</h2>
<help>
		OBSOLETE // use --cmdir instead
			FILE_CONTAINER:
			create directory  contentmine/some/where/journal.pone.0115884/. It may contain
			
			results.json * // a listing of scraped files
			
			fulltext.xml ? // publishers XML
			fulltext.pdf ? // publishers PDF
			fulltext.html ? // raw HTML
			provisional.pdf ? // provisional PDF (often disappears)
			
			foo12345.docx ? // data files numbered by publisher/author
			bar54321.docx ?
			ah1234.cif ? // crystallographic data
			pqr987.cml ? // chemistry file
			mmm.csv ? // table
			pic5656.png ? // images
			pic5657.gif ? // image
			suppdata.pdf ? // supplemental data
			
			and more
			
			only results.json is mandatory. However there will normally be at least one fulltext.* file and probably at 
			least one *.html file (as the landing page must be in HTML). Since quickscrape can extract data without 
			fulltext it might also be deployed against a site with data files.
			
			There may be some redundancy - *.xml may be transformable into *.html and *.pdf into *.html. The PDF may also 
			contain the same images as some exposed *.png.
		</help>
<h2>argument <tt>output</tt>
</h2>
<code>--output file_or_directory{1,1}</code>
<br>
<em>b: -o h:   c: </em>
<h2>Description</h2>
<help>
			OUTPUT
			 Output is to local filestore ATM. If there is only one input
			after wildcard expansion then a filename can be given. Else the argument must be a writeable directory; Norma
			will do her best to create filenames derived from the input names. Directory structures will not be preserved
			See also --recursive and --extensions",
		</help>
<h2>argument <tt>recursive</tt>
</h2>
<code>--recursive {1,1}</code>
<br>
<em>b: -r h:   c: </em>
<h2>Description</h2>
<help>
			RECURSIVE
			input directories
			If the input is a directory then by default only the first level is searched
			if the --recursive flag is set then all files in the directory tree may be input
			See also --extensions
		</help>
<h2>argument <tt>extensions</tt>
</h2>
<code>--extensions ext1 [ext2...]{1,*}</code>
<br>
<em>b: -e h:   c: </em>
<h2>Description</h2>
<help>
			EXTENSIONS
				When a directory or directories are searched then all files are input by default
				It is possible to limit the search by using only certain extensions
				See also --recursive.
		</help>
<h2>argument <tt>summaryfile</tt>
</h2>
<code>--summaryfile summaryfile{1,1}</code>
<br>
<em>b:  h:   c: </em>
<h2>Description</h2>
<help>
		SUMMARY FILE
		Directory to write summaries to.
		</help>
<h2>argument <tt>help</tt>
</h2>
<code>--help  {0,0}</code>
<br>
<em>b: -h h:   c: </em>
<h2>Description</h2>
<help>
			HELP
				outputs help for all options, including superclass DefaultArgProcessor
		</help>
<h2>argument <tt>args2html</tt>
</h2>
<code>--args2html  {0,0}</code>
<br>
<em>b:  h:   c: </em>
<h2>Description</h2>
<help>
	      
<p>Create HTML version of all args.xml file for inclusion in documentation</p>
	      
<p>Iterates over <tt>src/main/resources</tt> diretory to find all <tt>args.xml</tt> files
	      and creates a sister <tt>args.html</tt> file.</p>
	    
</help>
</div>
</html>
